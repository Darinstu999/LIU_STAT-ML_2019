{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Simple OOP and numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Student:__ Zhixuan_Duan(zhidu838)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-oriented Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of Object-oriented Programming is to support encapsulation and the DRY (Don't Repeat Yourself) principle without things getting out of hand. Often, software architects (those high-level programmers who are responsible for how large systems are designed on a technical level) talk about Object-oriented design or Object-oriented analysis. The point of this is to identify the necessary _objects_ in a system. An object in this sense is not exactly the same as a Python object but rather a somewhat higher level logical unit which can reasonably be thought of as an independent component within the system. These high level objects might then be further subdivided into smaller and smaller objects and at a some level the responsibility shifts from the system architect to the team or individual developer working on a specific component. Thus, Object-oriented thinking is necessary for anyone developing code which will be integrated with a larger system, for instance a data scientist implementing analytics tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python implements the Object-oriented paradigm to a somewhat larger degree than the Functional paradigm. However, there are features considered necessary for _strict_ object-oriented programming missing from Python. Mainly, we are talking about data protection. Not in a software security sense, but in the sense of encapsulation. There is no simple way to strictly control access to member variables in Python. This does not affect this lab in any way but is worth remembering if one has worked in a language such as Java previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple instance tests in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: some of these questions will be extremely simple, and some might prove trickier. Don't expect that the answer needs to be hard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.age = 0            # Age should be non-negative.\n",
    "        \n",
    "    def get_age(self):\n",
    "        \"\"\"Return the Person's age, a non-negative number.\"\"\"\n",
    "        return self.age\n",
    "    \n",
    "    def return_five(self):\n",
    "        \"\"\"Return 5. Dummy function.\"\"\"\n",
    "        return 5\n",
    "\n",
    "Jackal = Person \n",
    "\n",
    "president = Person(\"Jeb\")\n",
    "psec = Jackal(\"CJ Cregg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Change the age of the `president` to 65 (`psec` should be unaffected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#president.age = 65\n",
    "president.get_age()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note: This mode of operation is sometimes considered poor OOP. We will remedy this later.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) How many `Person` instances are there? One, two or three?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Consider the following code snippets. What do you think that they will return, and why? Discuss amongst yourselves. After that, run the code and explain the output. You only need to write down your explanation of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Jeb\" is Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "president is Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They will return False, because 'Jeb' is the name attribute of instance president, \n",
    "# and president is one instance of class 'Person'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) How would you go about checking whether or not the value bound to the name `president` is-a `Person`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(president, Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create class `Employee`, a subclass of `Person` with data attributes (fields) \n",
    "* `__work_days_accrued`\n",
    "* `__daily_salary`. \n",
    "\n",
    "These should be *the only* data attributes which you write in your class definition. In particular, you may not duplicate `name` and `age`.\n",
    "\n",
    "There should be methods\n",
    "* `work` which increments the number of work days accrued.\n",
    "* `expected_payout` which just returns the expected payout for the employee based on the accrued work days and daily salary (but without doing any resets).\n",
    "* `payout` which returns the accrued salary and resets the number of work days accrued. The `payout` function may not perform any calculations itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here.\n",
    "class Employee(Person):\n",
    "\n",
    "    def __init__(self,name,daily_salary = 15):\n",
    "        Person.__init__(self,name)\n",
    "        self.__daily_salary = daily_salary\n",
    "        self.__work_days_accrued = 0\n",
    "\n",
    "    def work(self):\n",
    "        self.__work_days_accrued += 1\n",
    "    \n",
    "    def expected_payout(self):\n",
    "        return(self.__work_days_accrued * self.__daily_salary)\n",
    "    \n",
    "    def payout(self):\n",
    "        old_payout = self.expected_payout()\n",
    "        self.__work_days_accrued = 0\n",
    "        return(old_payout)\n",
    "\n",
    "\n",
    "# Ready-made tests.\n",
    "print(\"--- Setting up test cases.\")\n",
    "cleaner = Employee(name = \"Scruffy\")  # Should have daily_salary 15.\n",
    "josh = Employee(name = \"Josh\", daily_salary = 1000)\n",
    "toby = Employee(name = \"Toby\", daily_salary = 9999)\n",
    "\n",
    "josh.work()\n",
    "josh.work()\n",
    "toby.work()\n",
    "toby.work()\n",
    "toby.work()\n",
    "cleaner.work()\n",
    "\n",
    "print(\"--- Testing payout and expected_payout properties.\")\n",
    "assert cleaner.expected_payout() == 15, \"default salary should be 15\"\n",
    "assert josh.expected_payout() == 1000*2\n",
    "assert josh.payout() == 1000*2\n",
    "assert josh.expected_payout() == 0, \"salary should be reset afterwards\"\n",
    "assert toby.payout() == 9999*3, \"toby and josh instances should be independent.\"\n",
    "print(\"OK\")\n",
    "\n",
    "print(\"--- Testing non-data-accessing calls to superclass methods.\")\n",
    "assert josh.return_five() == 5, \"Person.return_five should be accessible\"\n",
    "print(\"OK\")\n",
    "\n",
    "print(\"--- Testing data that should be set up by initialiser call.\")\n",
    "assert josh.get_age() == 0, \"superclass method should be callable, values should not be missing.\"\n",
    "josh.age = 9\n",
    "assert josh.get_age() == 9, \"superclass method should be callable\"\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Which public data attributes (fields) does an `Employee` have? Can you access the age of an employee directly (without some transformation of the name)? The daily salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee has name and age public attributes.\n",
    "# Yes, because the age attribute inherit from the father class.\n",
    "# No, because the daily_salary attribute is defined within the class.\n",
    "print(josh.age)\n",
    "print(toby.age)\n",
    "print(josh.daily_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Introductory numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of computations will likely end up using data stored `numpy` arrays. Therefore, it is a good idea to have a feeling for how they are used and manipulated. The following steps will provide some introduction, so that we can build upon this in future labs.\n",
    "\n",
    "You may want to refer to the [official numpy.org absolute beginners guide to numpy](https://numpy.org/devdocs/user/absolute_beginners.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Import the module `numpy`, giving it the shorthand `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create the $2 \\times 3$ matrix $A = \\begin{bmatrix}1 & 2 & 3 \\\\ 0 & 0 & 1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([(1,2,3),(0,0,1)])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Create the vector $b = \\begin{bmatrix}1\\\\ 2 \\\\ 3 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1,2,3]).reshape(3,1)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Perform the multiplication $Ab$. What is the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Mathematically, what should the dimensions of $b^Tb$ be? What should the dimensions of $bb^T$ be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The b is a 3x1 matrix, so b_T is a 1x3 matrix.\n",
    "\n",
    "According to matrix multiplication rule, b_T x b is a 1x1 matrix, and b x b_T shoule be a 3x3 matrix.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compute ```b.T @ b```? ```b @ b.T``` in numpy. How would you go about calculating $bb^T$ (if you wanted to actually store it as a matrix, which is rarely the most space- or time-efficient idea)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_T = b.transpose()\n",
    "print(b_T @ b)\n",
    "print(b @ b_T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: as `a @ b` is read `a.dot(b)` this should perhaps not be entirely surprising. But it is non-obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Try to solve the equation $Ax = b$ using the `solve` method. Does this make mathematical sense? What does numpy say? Read the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It returns 'LinAlgError: Last 2 dimensions of the array must be square'.\n",
    "\n",
    "Because numpy.linalg.solve uses LA gesv, which requires A to be a square matrix. But in our case, its not.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Try to solve the equation $A^Tx = b$ using numpy. Does this make mathematical sense? What does numpy say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.solve(A.transpose(),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It still errors, since the transpose of A is a 3x2 matrix, and its not a square matrix.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) One of the two tasks above make sense from a mathematical point of view. Find a best solution $x$ in the least squares sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The e task make sense, since A_T is a 3x2 matrix and b is a 3x1 matrix, which means x should be a 2x1 matrix\n",
    "# to fulfill the matrix multiplication law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "x,_,_,_ = numpy.linalg.lstsq(A.transpose(), b, rcond=None)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Is the resulting $Ax$ or $A^Tx$ (depending on your choice above) close to $b$? What is the norm-2-distance between the vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.linalg.norm(A.transpose() @ x - b)\n",
    "# It is close to b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get some practice, run the following to get some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn\n",
    "\n",
    "import sklearn.datasets as ds\n",
    "houses = ds.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) How many rows does the dataset have? Columns? Find out using numpy. (First check what `houses` actually is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRow = houses.data.shape[0]\n",
    "print(nRow)\n",
    "nCol = houses.data.shape[1]\n",
    "print(nCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Get the third column (remember: indexing starts at zero, so column number 2) of the dataset by indexing/slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(houses.data[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Get the values of the third, fourth and hundredrth rows (that is, index 2, 3, 99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(houses.data[(2,3,99),:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Mathematical sanity check: without actually computing the rank of ```houses.data```, can you provide a bound? Could it have $10^{15}$ linearly independent rows? 2000? Etc. Write down the tightest bound you can find, and explain why briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to look at some properties of the matrix here.\n",
    "print(houses.data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rank of a matrix is the latitude of column vector.\n",
    "\n",
    "# So in the houses.data, the number of column is 8, so the rank is up to 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Find out the actual rank of the matrix using numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.linalg.matrix_rank(houses.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. A simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this section is to build a naïve subspace-projection based classifier which takes a numerical vector and produces a label. We will build this from the ground up (there are many libraries that perform this automatically, but may not use them in this case).\n",
    "\n",
    "We will first practice our numpy (and linear algebra) skills to build the algorithm, and then encapsulate data and methods in a class. We will be taking a slightly different route than more general SVD methods for finding principal components, simply because this is not our task. This is worth remembering if you find material on the subject!\n",
    "\n",
    "The main idea here is to pick out all the data corresponding to a certain set of vectors, and reduce this matrix to some rank $\\leq k$ matrix which is a good approximation of the row space in some sense (here: the sense that the vectors correspond to maximal singular values). A naïve classification is then given by picking the subspace which is closest by orthogonal projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import some data. Here we use the classic MNIST data set of handwritten digits. We can naturally partition the sets of vectors used for training and validation in many ways. Feel free to experiment with a nicer (possibly non-deterministic) version later. This is only to get us started, and to have a set of data with known properties (which is helpful for lab assistants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as ds\n",
    "digits = ds.load_digits()\n",
    "training_digits = digits.data[0:600, :]\n",
    "training_labels = digits.target[0:600]\n",
    "# The set of labels can be found in digits.target_names."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we are curious, we can view the images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "# We show one of the digits.\n",
    "d_index = 2\n",
    "plt.imshow(training_digits[d_index].reshape(8,8))\n",
    "plt.xlabel(f\"Index: {d_index}, actually the number {training_labels[d_index]}\")\n",
    "# Note: digits.images[i] is the same as digits.data[i], but in 8x8 format (no need to reshape).\n",
    "# We would however like to stress that the 64 pixel images we'll be working with are stored in vector format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Get all rows with label 4. Store that in the matrix $A_4$. Similarly for $A_9$. This should be two single lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = training_digits[training_labels == 4,:]    # Replace with your code.\n",
    "a9 = training_digits[training_labels == 9,:]    # Replace with your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compute the thin SVD $A_4 = U_4\\Sigma_4 V^T_4$ and similarly for $A_9$. Thin here means that you do not necessarily get the full-rank square $U,V^T$ matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "U4,sigma4,VT4 = numpy.linalg.svd(a4, full_matrices = False)\n",
    "U9,sigma9,VT9 = numpy.linalg.svd(a9, full_matrices = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Our data is stored by row (one row per digit). What we use the different matrices in the decomposition for is thus slightly different than if it was stored by column. Instead of picking the best $k$ columns of $U$ we pick the best $k$ rows of $V^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let $sample4$ be the first row of $A_4$ and $sample9$ be the first row of $A_9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample4 = a4[0:1,:]\n",
    "sample9 = a9[0:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Let $R$ be the first 3 rows of $V^T$. Compute the orthogonal projection of $sample4$ onto the row space of $R_4$, and onto the row space of $R_9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = VT4[0:3,:]  # Your code here.\n",
    "r9 = VT9[0:3,:]  # Your code here\n",
    "\n",
    "coeffs_in_r4 = sample4 @ r4.T  # What are the coordinates of sample4 orthogonally projected onto R4?\n",
    "coeffs_in_r9 = sample9 @ r9.T\n",
    "\n",
    "sample4_in_r4 = coeffs_in_r4 @ r4   # Linear combination of rows in R4\n",
    "sample4_in_r9 = coeffs_in_r9 @ r9   # Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mathematical aside: where did the $\\Sigma$ go? This is a very important matrix, and strongly affects both interpretations and (in general) row- and column spaces. *Assuming* that the rank is $\\geq 3$ the row spaces should be the same whether or not we scale the basis vectors by some $\\sigma_i$ (since $\\sigma_i > 0$ for all $i=1,2,\\ldots, r$). That is enough for our application, though the interpretations of the vectors might be different. The rank assumption is rather important, and we will make rather casually based on knowledge about the data set. Later, we'll include a check for this in our code.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Which of the projections is closest to sample4 (in the sense that the difference (sample4_in_z**?**t - sample4) as the smallest 2-norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist4 = numpy.linalg.norm(sample4_in_r4 - sample4)\n",
    "dist9 = numpy.linalg.norm(sample4_in_r9 - sample4)\n",
    "print(dist4)\n",
    "print(dist9)\n",
    "dist4 < dist9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Create a function `split_data(data, data_labels, labels)` which takes a matrix of data (such as `training_data`), the labels of all rows (such as `training_labels`) and a vector of the labels (here the numbers 0,...,9) and returns a dictionary mapping a label to the matrix of all corresponding data. \n",
    "\n",
    "Here the dictionary would for instance have the key 2, and the corresponding value be the matrix of all the images in `data` classified as the number 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, data_labels, labels):\n",
    "    full_dict = {}\n",
    "    \n",
    "    for label in labels:\n",
    "        data_label = data[data_labels == label,:]\n",
    "        full_dict[label] = data_label\n",
    "    return full_dict\n",
    "split = split_data(training_digits, training_labels, digits.target_names)\n",
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Create a function `subspaces(labelled_data, k = 3)` that takes a dictionary such as above, and returns a dictionary mapping every occurring label $d$ to the respective $Z_d$ matrix with at most $k$ rows. Here the $Z_d$ matrices is defined as above, the best norm-2-approximation. If a particular matrix has a rank $r < k$, we should only keep $r$ rows (say, if there were many more *different* digit 9-rows in the training set, than digit 1:s)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subspaces(labelled_data, k = 3):\n",
    "    import numpy as np\n",
    "    sub_dict = {}\n",
    "    \n",
    "    for label,matrix in labelled_data.items():\n",
    "        k = min(np.linalg.matrix_rank(matrix),k)\n",
    "        U,s,VT = np.linalg.svd(matrix, full_matrices = False)\n",
    "        sub_dict[label] = VT[0:k]\n",
    "    \n",
    "    return sub_dict\n",
    "sub = subspaces(split)\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Create a function `classification(spaces, x)` that takes a dictionary such as produced by `subspaces` above and a single vector and produces the label of the subspace with the smallest norm-2-distance. In the task above, this would have meant that classifying $sample4$ would have produced the label 4 rather than 9, since $sample4$ was closer to the subspace $Z_4$ than the subspace $Z_9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(spaces, x):\n",
    "    import numpy as np\n",
    "    \n",
    "    distance = []\n",
    "    dist_index = ()\n",
    "    \n",
    "    for label,matrix in spaces.items():\n",
    "        coeffs = x @ spaces[label].T\n",
    "        sample = coeffs @ spaces[label]\n",
    "        distance.append(numpy.linalg.norm(sample - x))\n",
    "    \n",
    "    dist_index = list(zip(distance,sub.keys()))\n",
    "    index = min(dist_index)[1]\n",
    "    return index\n",
    "\n",
    "classification(sub, sample4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Now pick the first 600 rows as training and the remaining (about 1100) as validation sets. What percentage does the classifier get right? What happens if you pick $k = 5, 10, 100, 1000$? Try it out. (The sharp-eyed student will notice that not all of these choices make sense from a mathematical perspective.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_digits = digits.data[600:,]\n",
    "validation_labels = digits.target[600:]\n",
    "\n",
    "k = [5,10,100,1000]\n",
    "\n",
    "perc = {}\n",
    "split = split_data(validation_digits,validation_labels,digits.target_names) \n",
    "\n",
    "for i in k:\n",
    "    sub = subspaces(split,i)\n",
    "    labels = list(map(lambda x:classification(sub,x),validation_digits)) \n",
    "    perc[i] = sum(labels == validation_labels)/len(validation_labels)*100\n",
    "  \n",
    "perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Encapsulating the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have a set of functions floating around in a global namespace. If we change some data and rerun some cells, we might get unexpected results. We instead want to encapsulate this in a single class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create a class `NaiveProjection`. It should have the following properties:\n",
    "* An instance is created with `NaiveProjection(training_data, training_labels, all_labels, k)` where $k$ is optional (and defaults to 3). \n",
    "\n",
    "For instance, we should be able to run ```dig_class = NaiveProjection(training_data = digits.data[0:600,:], training_labels = digits.target[0:600], all_labels = digits.target_names)```.\n",
    "* The class should have a method called `classification` which takes vector and returns the classification of that vector as defined above (minimum 2-norm distance to the subspace).\n",
    "* The class should have a method called `hitrate` which takes a matrix of row vectors, a vector of correct labels and returns the rate of successfully classified \n",
    "* All data about subspaces and labels should be stored within the instance. We may not use any data stored outside (though it is of course OK to call outside functions). We should be able to create two (or more) independent classifiers\n",
    "\n",
    "```\n",
    "dig15 = NaiveProjection(digits.data[0:600, :], digits.target[0:600], k = 15)\n",
    "dig1 = NaiveProjection(digits.data[0:600, :], digits.target[0:600], k = 1)\n",
    "```\n",
    "which should be entirely independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveProjection:\n",
    "    def __init__(self,training_data,training_labels,all_labels,k=3):\n",
    "        self.training_data = training_data\n",
    "        self.training_labels = training_labels\n",
    "        self.all_labels = all_labels\n",
    "        self.k = k\n",
    "        self.split_data = self.split_data()\n",
    "        self.subspaces = self.subspaces()\n",
    "        \n",
    "    def split_data(self):\n",
    "        output = {}\n",
    "    \n",
    "        for label in self.training_labels:\n",
    "            data_labeled = self.training_data[self.training_labels == label,:]\n",
    "            output[label] = data_labeled\n",
    "        return output\n",
    "    \n",
    "    def subspaces(self):\n",
    "        import numpy as np\n",
    "        out = {}\n",
    "    \n",
    "        for label,matrix in self.split_data.items():\n",
    "            k = min(np.linalg.matrix_rank(value),self.k)\n",
    "            U,s,VT = np.linalg.svd(matrix, full_matrices = False)\n",
    "            out[label] = VT[0:self.k]\n",
    "    \n",
    "        return out\n",
    "\n",
    "    def classification(self, x):\n",
    "        import numpy as np\n",
    "        \n",
    "        distance = []\n",
    "        dist_index = ()\n",
    "        \n",
    "        for label, matrix in self.subspaces.items():\n",
    "            coeffs = x @ self.subspaces[label].T\n",
    "            sample = coeffs @ self.subspaces[label]\n",
    "            distance.append(np.linalg.norm(sample - x))\n",
    "        \n",
    "        dist_index = list(zip(distance, self.subspaces.keys()))\n",
    "        index = min(dist_index)[1]\n",
    "        return index\n",
    "    \n",
    "    def hitrate(self,validation_digits,validation_labels):\n",
    "        labels = list(map(lambda x: self.classification(x), validation_digits)) \n",
    "        perc = sum(labels == validation_labels)/len(labels)*100\n",
    "        return perc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate for k = 1: 84.7953216374269\n",
      "Hit rate for k = 15: 96.74185463659147\n"
     ]
    }
   ],
   "source": [
    "# You can test here\n",
    "dig1 = NaiveProjection(digits.data[0:600, :], digits.target[0:600], digits.target_names, k = 1)\n",
    "dig15 = NaiveProjection(digits.data[0:600, :], digits.target[0:600], digits.target_names, k = 15)\n",
    "\n",
    "print(f\"Hit rate for k = 1: {dig1.hitrate(digits.data[600:], digits.target[600:])}\")\n",
    "print(f\"Hit rate for k = 15: {dig15.hitrate(digits.data[600:], digits.target[600:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several noteworthy issues here.\n",
    "* We have taken a few mathematical shortcuts.\n",
    "* There is no error handling. \n",
    "* We have not discussed overlapping subspaces, sampling strategies or the like.\n",
    "* It might make a lot more sense to classify a matrix of vectors, rather than a single vector (to utilise the speed of computations). \n",
    "\n",
    "Most of this is left to an actual statistics course. The interested reader is referred to for instance Strang - Linear algebra and learning from data, or Golub & van Loan - Matrix computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Experiment with different values of $k$ and training data/validation data sets. Plot the results using the library ```matplotlib```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_digits = digits.data[0:300, :]\n",
    "training_labels = digits.target[0:300]\n",
    "\n",
    "validation_digits = digits.data[300:,]\n",
    "validation_labels = digits.target[300:]\n",
    "\n",
    "\n",
    "k = range(10)\n",
    "valid = []\n",
    "for i in k:\n",
    "    t = NaiveProjection(training_digits, training_labels, digits.target_names, k = i)\n",
    "    valid.append(t.hitrate(validation_digits, validation_labels))\n",
    "\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "\n",
    "mpl.figure()\n",
    "mpl.plot(k,valid)\n",
    "mpl.xlabel('K')\n",
    "mpl.ylabel('Successful rate')\n",
    "mpl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab in 732A74 is by Anders Märak Leffler (2019), with a major revision in 2020. The introductory text is by Johan Falkenjack (2018).\n",
    "\n",
    "Licensed under [CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
